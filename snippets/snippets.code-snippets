{
	"TestCase Best Practice Checklist": {
		"prefix": "rf_doc_case_checklist",
		"body": [
            "$BLOCK_COMMENT_START",
			"- print case doc to test debug log",
			"- print running parameters to debug log",
			"- print full cmd(with options) executed to debug log",
			"  eg. INFO:CMD: sudo rpm -V efi-filesystem",
			"- print cmd output and ret to debug log instead of dropping them silently",
			"  eg. dmesg|grep error >/dev/null 2>&1 (bad example)",
			"- cover similar scenario instead of only specific one",
			"  eg. switch all available tracer instead of only the bz mentioned 1650273",
			"      for tracer in $(cat /sys/kernel/debug/tracing/available_tracers); do ",
			"          echo $tracer > /sys/kernel/debug/tracing/current_tracer",
			"      done",
			"- try it before you submit your changes",
            "$BLOCK_COMMENT_END"
		],
		"description": "TestCase best practice checklist, think more in new case design."
	},
    "TestCase Doc Template": {
		//"scope": "python,c",
		"prefix": "rf_doc_case_docstring",
		"body": [
			"$BLOCK_COMMENT_START",
			"case_name:",
            "    <testcase name>",
			"case_tags:",
            "    <testcase tag. eg. tagA,tagB>",
			"case_status:",
            "    <testcase status in test management system. default is Approved - Evidence Traceability>",
			"title:",
            "    <Human readable title - short (not a description) - Evidence Traceability>",
			"importance:",
            "    <Low, Medium, High, Critical> - Evidence Traceability",
			"subsystem_team:",
            "    <The Jira label used to identify the responsible QE SST. eg. sst_virtualization_cloud - Evidence Traceability>",
			"automation_drop_down:",
            "    <Default is Automated in test suite already,other options, Not Automated,Manual Only - Evidence Traceability>",
			"linked_work_items:",
            "    <Prefix with the ticket id:jira_XXXX, polarion_XXXX, better to not paste full url here>",
			"automation_field:",
			"    <link to Git Repo for the automated test(the case code location).>",
			"setup_teardown:",
			"    <Setup, pre-conditions, and teardown required to perform the test case>",
			"environment:",
			"    <Environment conditions and configurations specific to the test case or sth like CPU memory:  <=512>",
			"component:",
            "    <which component this case tests for - Evidence Traceability>",
            "bug_id:",
            "    <N/A, jira_XXXX or bugzilla_XXXX, better to not paste full url here - Evidence Traceability>",
			"is_customer_case:",
            "    <True or False - Evidence Traceability>",
            "testplan:",
			"    <optional: N/A or testplan location>",
			"test_type:",
			"    <default is Functional - Evidence Traceability>",
			"test_level:",
			"    <default is Component - Evidence Traceability>",
			"maintainer:",
            "    <case's maintainer - Evidence Traceability>",
            "description: |",
			"    <Describe the test case intent - Evidence Traceability>",
			"key_steps: |",
            "    <case key steps - Evidence Traceability>",
            "expected_result: |",
			"    <pass criterial - Evidence Traceability>",
			"debug_want: |",
            "    <optional: N/A or debug information required when file new bug if case failed>",
            "$BLOCK_COMMENT_END"
		],
		"description": "Doc template for test case."
	},
	"Python Argparse Quick Start": {
		"scope": "python",
		"prefix": "rf_py_argparse",
		"body": [   
			"import argparse",
			"parser = argparse.ArgumentParser(description='The tool simple description')",
			"parser.add_argument('-d', dest='is_debug', action='store_true',help='run in debug mode', required=False)",
			"parser.add_argument('-f', dest='file', default=None, action='store',help='specify file location', required=False)",
			"args = parser.parse_args()",
			"print('access args demo {}.format(args.file)')",
			"# https://docs.python.org/3.8/library/argparse.html"
		],
		"description": "Python argparse snippet"
	},
	"Python Run in Parallel": {
		"scope": "python",
		"prefix": "rf_py_concurrent.futures",
		"body": [
			"import concurrent.futures",
			"def run_single(x):",
            "    print('I am {}, can do something else.'.format(x))",
			"with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:",
			"    all_jobs = {executor.submit(run_single, ts): ts for ts in range(10)}",
			"    for r in concurrent.futures.as_completed(all_jobs, timeout=60):",
			"        x = all_jobs[r]",
			"        try:",
			"            data = r.result()",
			"        except Exception as exc:",
			"            print('{} generated an exception: {}'.format(r,exc))",
			"        else:",
			"            pass",
		],
		"description": "Python run in parallel snippet"
	},
	"Python CSV File Read": {
		"scope": "python",
		"prefix": "rf_py_csv_read",
		"body": [
			"import csv",
			"with open('demo.csv') as fh:",
            "    csv_data = csv.DictReader(fh)",
			"    for row in csv_data:",
			"        print('{}{}'.format(row['head1'],row['head2']))",
		],
		"description": "Python csv file dic read"
	},
	"Python CSV File Write": {
		"scope": "python",
		"prefix": "rf_py_csv_write",
		"body": [
			"import csv",
			"headers = ['head1','head2','head3']",
			"rows = [{'head1':'test1','head2':'test2','head3':'test3'},",
			"        {'head1':'test4','head2':'test5','head3':'test6'},",
			"        {'head1':'test7','head2':'test8','head3':'test9'}]",
			"with open('demo.csv', 'w+') as fh:",
			"    csv_data = csv.DictWriter(fh, headers)",
			"    csv_data.writeheader()",
			"    csv_data.writerows(rows)",
			"# https://docs.python.org/3.8/library/csv.html"
		],
		"description": "Python csv file dic write"
	},
	"Python Logging Quick Start": {
		"scope": "python",
		"prefix": "rf_py_logging",
		"body": [
			"import logging",
			"LOG_FORMAT = '%(asctime)s:%(levelname)s:%(message)s'",
			"LOG = logging.getLogger(__name__)",
			"logging.basicConfig(level=logging.DEBUG, format=LOG_FORMAT)",
			"LOG.info('Ready to work now!')",
			"LOG.debug('Here is debug information')",
			"# https://docs.python.org/3.8/library/logging.html"
		],
		"description": "Python logging snippet"
	},
	"Python Signal Quick Start": {
		"scope": "python",
		"prefix": "rf_py_signal",
		"body": [
			"import signal",
			"def sig_handler(signum, frame):",
			"    print('Got signal {}, call cleanup and exit! Waiting......'.format(signum))",
			"    do_cleanup()",
			"    sys.exit(0)",
			"signal.signal(signal.SIGHUP, sig_handler)",
			"signal.signal(signal.SIGINT, sig_handler)",
			"signal.signal(signal.SIGQUIT, sig_handler)",
			"signal.signal(signal.SIGTERM, sig_handler)",
			"# https://docs.python.org/3.8/library/signal.html"
		],
		"description": "Python signal handler snippet"
	},
	"Python Timeout Control": {
		"scope": "python",
		"prefix": "rf_py_timeout",
		"body": [
			"import time",
			"timeout = 120",
			"interval = 2",
			"time_start = int(time.time())",
			"while True:",
			"   #todo here",
			"   time_end = int(time.time())",
			"   if time_end - time_start > timeout:",
			"      print('timeout ended: {}'.format(timeout))",
			"      break",
			"   print('retry after {}s'.format(interval))",
			"   time.sleep(interval)",
		],
		"description": "Python timeout snippet"
	},
	"Python Yaml Quick Start": {
		"scope": "python",
		"prefix": "rf_py_yaml",
		"body": [
			"try:",
			"    from yaml import load, dump",
		    "    from yaml import CLoader as Loader, CDumper as Dumper",
		    "except ImportError:",
			"    from yaml import Loader, Dumper",
			"with open(cfg_file,'r') as fh:",
            "    keys_data = load(fh, Loader=Loader)",
			"print(keys_data['xxxx'])",
			"data=load(p.__doc__,Loader=Loader)",
			"dump(data,fh) # dump to file",
			"print(dump(data)) # print to stdout",
			"# https://pyyaml.org/wiki/PyYAMLDocumentation"
		],
		"description": "Python yaml snippet"
	},
}